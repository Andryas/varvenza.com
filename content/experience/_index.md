---
title: "Work Experience"
draft: false
date: 2023-10-18
layout: "simple"
---

Email: Andryaas@gmail.com  
Education: Bachelor's Degree in Statistics at Federal University of Paraná | 2014 - 2019  
Languages: Portuguese (primeira), English (fluent), French (débutant), Spanish (entiendo)

{{< chart >}}
type: 'radar',
data: {
  labels: [
    'Programming',
    ['Statistics and', ' probability'],
    ['Data wrangling and', 'database management'],
    ['Machine learning and', 'deep learning'],
    ['Data', 'visualization'],
    ['Cloud', 'computing'],
    ['Interpersonal', 'skills']
  ],
  datasets: [{
    label: 'Andryas Wavrzenczak',
    data: [90, 80, 85, 50, 95, 50, 80],
    fill: true,
    backgroundColor: 'rgba(59, 130, 246, 0.5)',
    borderColor: 'rgb(59, 130, 246)',
    pointBackgroundColor: 'rgb(59, 130, 246)',
    pointBorderColor: '#fff',
    pointHoverBackgroundColor: '#fff',
    pointHoverBorderColor: 'rgb(59, 130, 246)'
  }]
},
options: {
    elements: {
      line: {
        borderWidth: 3
      }
    },
    scales: {
        r: {
            angleLines: {
                display: false
            },
            pointLabels: {
              font: {
                 beginAtZero: true,
                size: 17.5
              }
            },
            suggestedMin: 0,
            suggestedMax: 100
        }
    },
     plugins: {
            legend: {
                display: false
            }
        }
  }
{{< /chart >}}

<div id="my_skills" style="display: flex;gap: 10px;flex-wrap: wrap;">
{{< badge >}}
R
{{< /badge >}}

{{< badge >}}
Python
{{< /badge >}}

{{< badge >}}
Shiny
{{< /badge >}}

{{< badge >}}
SQL
{{< /badge >}}

{{< badge >}}
MongoDB
{{< /badge >}}

{{< badge >}}
AWS
{{< /badge >}}

{{< badge >}}
GCP
{{< /badge >}}

{{< badge >}}
Webscraping
{{< /badge >}}

{{< badge >}}
Data Wrangling
{{< /badge >}}

{{< badge >}}
ElasticSearch
{{< /badge >}}

{{< badge >}}
JavaScript
{{< /badge >}}

{{< badge >}}
HTML
{{< /badge >}}

{{< badge >}}
CSS
{{< /badge >}}

{{< badge >}}
Git
{{< /badge >}}

{{< badge >}}
Ubuntu
{{< /badge >}}

{{< badge >}}
Mac
{{< /badge >}}

{{< badge >}}
Latex
{{< /badge >}}

{{< badge >}}
Rabbitmq
{{< /badge >}}

{{< badge >}}
Docker
{{< /badge >}}

{{< badge >}}
Scrapy
{{< /badge >}}

{{< badge >}}
Rmarkdown
{{< /badge >}}

{{< badge >}}
Caret
{{< /badge >}}

{{< badge >}}
Flask
{{< /badge >}}

{{< badge >}}
Golem
{{< /badge >}}



</div>

{{< timeline >}}

{{< timelineItem icon="mug-hot" header="CAPTAL | Data Scientist/Data Enginner" badge="2021/OCT-PRESENT" subheader=" São Paulo, Brazil" >}}
<ul>
  <li>Responsible for webscraping ecosystem</li>
  <li>Responsible for the real estate asset origination platform (developed in Shiny)</li>
  <li>Infrastructure maintainer on GCP and AWS</li>
  <li>Provide essential data support across various organizational areas, facilitating informed decision-making and strategy development. Collaborate with multiple teams, ensuring that relevant, accurate, and timely data was available for various projects and initiatives</li>
  <li>Deployed sophisticated statistical models aimed at optimizing property pricing strategies. Utilized advanced analytics and data-driven insights to enhance the accuracy and competitiveness of property pricing, contributing to organizational success and market competitiveness.</li>
</ul>
{{< /timelineItem >}}


{{< timelineItem icon="xmark" header="Gaia | CONSULTANT" badge="2022/MAY-2023-JUL" subheader="Cidade del Mexico, Mexico" >}}
<ul>
  <li>Engineered and developed a comprehensive crawler ecosystem specialized for e-commerce platforms, enhancing data extraction and analysis capabilities.</li>
  <li>Development of forecasting using approachs top-bottom and specifics </li>
  <li>Support with analytical reports</li>
</ul>
{{< /timelineItem >}}

{{< timelineItem icon="xmark" header="MadeiraMadeira | CONSULTANT" badge="2021/APR-2022-JAN" subheader="Curitiba, Brazil" >}}
<ul>
  <li>Revamped the scoring algorithm created by me previously, optimizing the arrangement of product listings to improve user experience and engagement in the website.</li>
  <li>Improved and maintained the software responsible for managing the scoring algorithm, ensuring its seamless operation and reliability.</li>
  <li>Provided comprehensive analytical support by generating insightful reports, conducting A/B tests, and measuring the effectiveness of marketing campaigns.</li>
</ul>
{{< /timelineItem >}}

{{< timelineItem icon="xmark" header="Kzas | Data Scientist" badge="2021/APR-2021-SEP" subheader="São Paulo, Brazil" >}}
<ul>
  <li>Developed web crawlers for efficient data extraction from various online sources.</li>
  <li>Established a robust data quality pipeline to ensure the integrity and accuracy of the collected data.</li>
  <li>Designed and implemented a comprehensive workflow for data enrichment processes.</li>
  <li>Successfully deployed an Automated Valuation Model (AVM) for accurate property pricing</li>
  <li>Launched an API for seamless model consumption by external systems.</li>
  <li>Introduced an interactive tool to enhance user experience and model accessibility</li>
</ul>
{{< /timelineItem >}}

{{< timelineItem icon="xmark" header="MadeiraMadeira | Statistical Analyst" badge="2019/NOV-2021-APR" subheader="Curitiba, Brazil" >}}
<ul>
  <li>Deployed a sophisticated forecast model to enhance prediction accuracy across all products.</li>
  <li>Conducted comprehensive studies to optimize product allocation between marketplaces, ensuring efficient distribution and maximized sales.</li>
  <li>Undertook text mining studies to garner customer perspectives, aiming to enhance the overall quality of sellers and customer satisfaction.</li>
  <li>Investigated and identified key gaps in delivery times, working towards optimizing and improving delivery efficiency.</li>
  <li>Implemented product clustering techniques, bolstering the effectiveness of product recommendations to customers.</li>
  <li>Introduced a scoring algorithm to optimize product arrangement, enhancing user navigation and product discoverability.</li>
  <li>Executed the implementation of ETL processes, facilitating accurate and efficient KPI calculations.</li>
  <li>Developed and conducted experimental A/B tests to evaluate the effectiveness of various marketing campaign strategies, driving optimization efforts.</li>
  <li>Created a web crawler to assess competitiveness, utilizing Google Shop as a primary data source, to refine and improve market positioning strategies.</li>
</ul>
{{< /timelineItem >}}

{{< timelineItem icon="xmark" header="Bradesco Bank | Statistical Intern" badge="2018/MAR-2019-JUL" subheader="Curitiba, Brazil" >}}
<ul>
  <li>Automation of the performance measurement process of default
models</li>
  <li>Support in the development of default models</li>
  <li>Study of time series of macroeconomic indicators for top management</li>
</ul>
{{< /timelineItem >}}

{{< /timeline >}}
